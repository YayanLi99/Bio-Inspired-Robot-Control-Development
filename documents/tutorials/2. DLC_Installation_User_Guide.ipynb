{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e83cdc1",
   "metadata": {},
   "source": [
    "# 1. DLC Installation Tutorial\n",
    "\n",
    "Prequisite\n",
    "- Install Anaconda [Done]\n",
    "- Install Git [Done]\n",
    "\n",
    "Note: the label [Done] means those steps are already be done in Lab PC."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c476127c",
   "metadata": {},
   "source": [
    "## 1.1 Install Anaconda [Done]\n",
    "\n",
    "Here we use anaconda to create virtual environment, you can also use python to create it.\n",
    "\n",
    "Install anaconda refer to the [official tutorial](https://www.anaconda.com/docs/getting-started/anaconda/install#macos-linux-installation)\n",
    "\n",
    "You can choose an initialization options:\n",
    "\n",
    "- Yes - conda modifies your shell configuration to initialize conda whenever you open a new shell and to recognize conda commands automatically.\n",
    "- No - conda will not modify your shell scripts. After installation, if you want to initialize, you must do so manually. For more information, see Manual shell initialization.\n",
    "\n",
    "### Manual Shell Initialization for anaconda\n",
    "\n",
    "Once installation has successfully completed, initialize your shell by running the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a184b53e",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Replace <PATH_TO_CONDA> with the path to your conda install\n",
    "source <PATH_TO_CONDA>/bin/activate\n",
    "conda init --all    # only need to run once"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb23a75",
   "metadata": {},
   "source": [
    "## 1.2 Create a new Enviroment [Done]\n",
    "\n",
    "This part only install CPU-only version Deeplabcut, you can label data using the Deeplabcut GUI, then train the data on Google Colab(GUI not supported) or other platforms.\n",
    "\n",
    "If you want to install Deeplabcut with pytorch GPU-supported version and train the data on PC, please continue to `1.2 DLC GPU support`.\n",
    "\n",
    "\n",
    "Download [`DEEPLABCUT.yaml`](https://github.com/DeepLabCut/DeepLabCut/blob/main/conda-environments/DEEPLABCUT.yaml) file from github \n",
    "\n",
    "open the program terminal/cmd/anaconda prompt as admin\n",
    "\n",
    "go to the folder that has the `.yaml` file, then run:\n",
    "\n",
    "Option 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2c4332",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "conda env create -f DEEPLABCUT.yaml\n",
    "\n",
    "# upgrade deeplabcut\n",
    "pip install --upgrade deeplabcut\n",
    "\n",
    "# install pytables to read HDF5 files\n",
    "conda install -c conda-forge pytables==3.8.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff1599c",
   "metadata": {},
   "source": [
    "Option 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7acb2bf4",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Or use the latest installation guide\n",
    "conda create -n DEEPLABCUT python=3.12\n",
    "conda activate DEEPLABCUT\n",
    "conda install -c conda-forge pytables==3.8.0\n",
    "\n",
    "# install the latest version of DeepLabCut\n",
    "pip install --pre deeplabcut\n",
    "# or if you want to use the GUI\n",
    "pip install --pre deeplabcut[gui]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b4141e",
   "metadata": {},
   "source": [
    "You can now use this env from anywhere on your PC(i.e., no need to go back into the conda-folder).\n",
    "Just enter your environment by running:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9713ea",
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "# you may need to source anaconda first\n",
    "source <PATH_TO_CONDA>(anaconda3)/bin/activate\n",
    "\n",
    "conda activate DEEPLABCUT\n",
    "\n",
    "# if you are using anaconda prompt, you can directly use:\n",
    "activate DEEPLABCUT           # Windows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8dceda6",
   "metadata": {},
   "source": [
    "To launch the deeplabcut by running(activate the env before running):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8d24d8",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "python -m deeplabcut"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae1d0a9",
   "metadata": {},
   "source": [
    "## 1.3 DLC GPU support [Done]\n",
    "\n",
    "- Install [GPU driver](https://www.nvidia.com/en-us/drivers/) (NVIDIA)\n",
    "- Install [CUDA toolkit](https://pytorch.org/get-started/locally/) [cuDNN is supplied inside the anaconda env]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc2e0a6",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# First, install a driver for your GPU in the link above\n",
    "# and check your GPU name\n",
    "nvida-smi\n",
    "\n",
    "\n",
    "# Second, install matching CUDA toolkit\n",
    "# Check the compatible CUDA version in the link above\n",
    "# option 1: conda install\n",
    "# use the following command to install pytorch with CUDA 11.3\n",
    "conda install pytorch cudatoolkit=11.3 -c pytorch\n",
    "\n",
    "# option 2: pip install\n",
    "# or for the latest CUDA 12.8\n",
    "pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu128\n",
    "\n",
    "\n",
    "# Final check\n",
    "# import python or ipython in the terminal\n",
    "python # or ipython\n",
    "\n",
    "# check your pytorch version\n",
    "# possible outputs: 2.7+cu128, or 2.7+CPU\n",
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())     # should return True\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a46f07",
   "metadata": {},
   "source": [
    "### 1.4 Check your GPU is working\n",
    "\n",
    "To check your GPU is working, create a project and train the network.\n",
    "Before training, make sure to configure the `pytorch_config.yaml` - `runner`\n",
    "\n",
    "First, in the terminal, run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3a4459",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "python \n",
    "import torch\n",
    "# count the number of your GPU, the id should starts from 0\n",
    "print(torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4160561",
   "metadata": {},
   "source": [
    "**MUST BE DONE!**\n",
    "\n",
    "So if you have 1 GPU, you should enter the value `[0]` or `- 0` into `pytorch_config.yaml`- `runner`-`gpus` key.\n",
    "\n",
    "Or you can find the `config.yaml` option in `training the network` in Deeplabcut GUI. Go to  `runner`-`gpus` and insert `[0]`\n",
    "\n",
    "Don't type `0`, it doesn't work.\n",
    "\n",
    "**Double Check** if the GPU is woking running the following command in a new terminal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7995e796",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# real time updates, look at `sm`[Streaming Multiprocessor] and `mem`\n",
    "nvidia-smi dmon\n",
    "\n",
    "# or look at GPU-Util value\n",
    "# Read Processes to see which program is running and the matching GPU Memory Usage, e.g. python\n",
    "nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7a35d8",
   "metadata": {},
   "source": [
    "\n",
    "If you donâ€™t see activity there during training, then your GPU is likely not installed correctly for DeepLabCut. \n",
    "\n",
    "Return to the installation instructions, and be sure you installed CUDA 11+, and ran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b847144",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "conda install cudnn -c conda-forge after installing DeepLabCut."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71d2cbe",
   "metadata": {},
   "source": [
    "# 2. User Guide\n",
    "\n",
    "## 2.0 Roadmap of Getting familiar with DLC\n",
    "\n",
    "Read the [documentation](https://deeplabcut.github.io/DeepLabCut/README.html) in this sequence:\n",
    "\n",
    "- Beginner's Level:\n",
    "    1. [Installation](https://deeplabcut.github.io/DeepLabCut/docs/installation.html) Chapter: You can follow the guide above instead of reading this part\n",
    "    1. [Beginner's Guide to DLC](https://deeplabcut.github.io/DeepLabCut/docs/beginner-guides/beginners-guide.html) Chapter: for GUI usage\n",
    "    1. [Quick Start Tutorials](https://deeplabcut.github.io/DeepLabCut/docs/quick-start/single_animal_quick_guide.html) Chapter: for terminal usage\n",
    "    1. [Getting Started with DLC: our key recommendation](https://deeplabcut.github.io/DeepLabCut/docs/UseOverviewGuide.html): some concepts and self-paced course for later learning\n",
    "\n",
    "- Intermediate:\n",
    "    1. [Main User Guide](https://deeplabcut.github.io/DeepLabCut/docs/standardDeepLabCut_UserGuide.html)\n",
    "    1. [self-paced course](https://deeplabcut.github.io/DeepLabCut/docs/course.html)\n",
    "    1. [Napari labeling GUI](https://deeplabcut.github.io/DeepLabCut/docs/gui/napari_GUI.html)\n",
    "    \n",
    "\n",
    "- Advanced:\n",
    "    1. [DLC3 PyTorch Specific Docs](https://deeplabcut.github.io/DeepLabCut/docs/pytorch/user_guide.html)\n",
    "    1. \n",
    "\n",
    "\n",
    "## 2.1 Create a Project\n",
    "\n",
    "First, activate anaconda `DEEPLABCUT` env.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893946bd",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# source anaconda in linux\n",
    "# source <path_to_anaconda>/bin/activate\n",
    "source anaconda3/bin/activate\n",
    "\n",
    "# activate DEEPLABCUT env\n",
    "conda activate DEEPLABCUT\n",
    "\n",
    "# Run deeplabcut GUI\n",
    "python -m deeplabcut"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615e34f5",
   "metadata": {},
   "source": [
    "Choose `create new project` button to configure your new project\n",
    "\n",
    "Then fill in the needed parameters, recommend to tick the `copy videos to project folder` to avoid some undelying warnings like `couldn't open the video` or so on.\n",
    "\n",
    "## 2.2 Edit config.yaml\n",
    "\n",
    "You should specify `body parts` and `numframes2pick` in the `config.yaml` file. You can fill it in the GUI or open the file in any text editor.\n",
    "\n",
    "## 2.3 Extract Frames\n",
    "\n",
    "[Recommended](https://deeplabcut.github.io/DeepLabCut/docs/UseOverviewGuide.html):\n",
    "\n",
    "A set of videos that span the types of behaviors you want to track.\n",
    "\n",
    "Having 10 videos that include different backgrounds, different individuals, and different postures is MUCH better than 1 or 2 videos of 1 or 2 different individuals \n",
    "\n",
    "**(i.e. 10-20 frames from each of 10 videos is much better than 50-100 frames from 2 videos).**\n",
    "\n",
    "Select videos, and configure the method to be used. Then click `Extract Frames`\n",
    "\n",
    "## 3. Label Frames\n",
    "\n",
    "### 3.1 3D project: [label your data use epipolar lines](https://deeplabcut.github.io/DeepLabCut/docs/HelperFunctions.html) [Optional]\n",
    "\n",
    "If you have multiple cameras, you may want to use epipolar lines projected on the images you are labeling to help you label the same position on the body in each camera angle. \n",
    "\n",
    "An epipolar line is a projection from one camera to all the possible points in the second cameraâ€™s image that could match the labeled point in the first cameraâ€™s image. A correctly labeled point will fall somewhere along this projected line.\n",
    "\n",
    "In order to label with epipolar lines, you must complete two additional sets of steps prior to labeling.\n",
    "\n",
    "- First, you must create a 3d project and calibrate the cameras\n",
    "\n",
    "- Second, you must extract image from camera_1 first; here you would have run the standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33ab920",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "deeplabcut.extract_frames(config_path, userfeedback=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4697291b",
   "metadata": {},
   "source": [
    "but just extract files from 1 camera. Next, you need to extract matching frames from camera_2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ff7143",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "deeplabcut.extract_frames(config_path, mode = 'match', config3d=config_path3d, extracted_cam=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aaea16b",
   "metadata": {},
   "source": [
    "You can set `extracted_cam=0` to match all other camera images to the frame numbers in the camera_1 folder, or change this to match to other cameras. \n",
    "\n",
    "If you `deeplabcut.extract_frames with mode='automatic'` before, it shouldnâ€™t matter which camera you pick. \n",
    "\n",
    "If you already extracted from both cameras, be warned this will overwrite the images for camera_2.\n",
    "\n",
    "- Three, now you can label with epipolar lines:\n",
    "\n",
    "Here, label camera_1 as you would normally, Then for camera_2 (now it will compute the epipolar lines based on camera_1 labels and project them onto the GUI):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c91a27c",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "deeplabcut.label_frames(config_path, config3d=config_path3d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa6addb",
   "metadata": {},
   "source": [
    "### 3.2 Napari GUI\n",
    "\n",
    "If the image couldn't show on the  napari GUI when you launch it from Deeplabcut GUI\n",
    "\n",
    "Close the napari GUI, then open a new terminal and activate DEEPLABCUT env again.\n",
    "\n",
    "Launch `napari` GUI in the new terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ce1c97",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# source anaconda in linux\n",
    "# source <path_to_anaconda>/bin/activate\n",
    "source anaconda3/bin/activate\n",
    "\n",
    "# activate DEEPLABCUT env\n",
    "conda activate DEEPLABCUT\n",
    "\n",
    "napari"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e032bc4a",
   "metadata": {},
   "source": [
    "Then load `keypoints control` in the `plugins` menu bar\n",
    "\n",
    "Open folders, only one layer shown there.\n",
    "\n",
    "Drag the config.yaml into napari GUI, the `CollectedData_Name` layers and the keypoints info set in the config.yaml will be shown.\n",
    "\n",
    "The key is to **load Plugins first**, open label folder and drag the config.yaml into the napari GUI.\n",
    "\n",
    "#### Start Labeling  \n",
    "\n",
    "You can see on the left side, there are two layers including `images` and `CollecteData_Name`. \n",
    "\n",
    "You should add label on the `CollectedData_Name` layer, click the `add points` button on the left top side on the layer controls pannel, or you can use shortcuts.\n",
    "\n",
    "Move your mouse to the `Keypoint selection` pannel then roll your mouse can switch keypoint.\n",
    "\n",
    "Discover how to use the GUI on your own, which can increase your productivity, especially when you need to mark many key points.\n",
    "\n",
    "Remember to save your changes before close it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86c1148",
   "metadata": {},
   "source": [
    "## 3.3 Create Training Dataset\n",
    "\n",
    "**NOTE:** only run this step where(Colab or your own PC) you are going to train the network\n",
    "\n",
    "If you label on your laptop but move your project folder to Google Colab or AWS, lab server, etc, then run the step below on that platform!\n",
    "\n",
    "If you labeled on a Windows machine but train on Linux, this is fine as of 2.0.4 onwards it will be done automatically (it saves file sets as both Linux and Windows for you).\n",
    "\n",
    "If you move your project folder, the project_path in the main config.yaml file is done automatically changed\n",
    "- no need to change the video paths, etc! Your project is fully portable\n",
    "\n",
    "You can create different training dataset by specifying an integer value to the `num_shuffles`\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### 3.4 Train The Network\n",
    "\n",
    "Recommended to train the network until the loss plateaus( 100-250 epochs)\n",
    "\n",
    "\n",
    "### 3.5"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
